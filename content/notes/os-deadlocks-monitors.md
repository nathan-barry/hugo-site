+++
title = "Deadlocks & Monitors"
description = ""
date = 2023-09-15T14:01:27-05:00
tags = ["Operating Systems Notes"]
status = "Work In Progress"
priority = 7
+++

{{< toc >}}



## Understanding Deadlocks
***

Deadlock arises when multiple threads wait for an event that can solely be generated by these very threads. An example is when two threads are each holding a lock that the other needs to acquire. Since neither can acquire the lock nor release their own, the program grinds to a halt. {{%sidenote%}}It's important to note: Deadlock is **not** starvation. Starvation can take place without any deadlock and it happens when a thread indefinitely waits for resources that are currently in use by other threads. However, every deadlock implies starvation. Our focus is on deadlocks in multi-threaded code.{{%/sidenote%}}

### Conditions for Deadlock

Deadlock happens when the following conditions are simultaneously true:

1. *Mutual Exclusion:* At least one thread holds a resource in a non-sharable mode.
2. *Hold and Wait:* A thread holds a resource and is awaiting others. A different thread possesses the desired resource.
3. *No Pre-emption:* Resources are only released by a thread voluntarily. Neither another thread nor the OS can force its release.
4. *Circular Wait:* There's a cyclic dependency among waiting threads {t1, ..., tn} where each thread ti waits on ti+1 and tn waits on t1.

### Deadlock Prevention

To prevent deadlock, ensure at least one of the aforementioned conditions doesn't hold. Below are possible solutions to break the condition:

1. *Mutual Exclusion:* Make resources shareable.
2. *Hold and Wait:* Ensure a thread cannot hold a resource when requesting another or must request all simultaneously.
3. *No Pre-emption:* If a thread's resource request cannot be immediately satisfied, the OS preempts all the resources the thread currently holds. The thread restarts only when all resources are available.
4. *Circular Wait:* Impose an order on the locks and request them sequentially.

Generally, circular wait is the easiest condition to prevent. For lock ordering in deadlock prevention, all code should acquire locks in a predefined sequence.

**Challenges:** Maintaining a global order in vast projects can be challenging. The global order might force one to obtain a lock earlier than needed, thus occupying the lock longer than required.



## Monitors
***

### Challenges with Semaphores

Semaphores were a significant advancement from previous techniques, yet they have shortcomings.
- They behave like shared global variables.
- They serve too many functions:
  - Waiting for a condition should be decoupled from mutual exclusion.
- There's no mechanism to ensure they're used correctly.
- Semaphore-driven code can be hard to understand and develop.

Semaphores are typically used in very low level systems: operating systems, databases, embedded systems, etc. For user code, we turn to a higher level synchronization construct: **Monitors**.

### Introduction to Monitors

A monitor integrates a lock and possibly multiple condition variables to manage concurrent access to shared data.
It employs the lock to confirm only a single thread is active within the monitor at any time.

This lock also guarantees mutual exclusion for the encapsulated shared data.
Condition variables allow threads to pause and wait for a specific event within critical sections. When a thread sleeps, the lock is concurrently released.

- *Purpose*: Monitors encapsulate shared data.
  - Group associated shared data into logical units, akin to structs or files in C.
- *Privacy*: All data within a monitor is private.
- *Access*: Operations on shared data are defined as functions.
  - These functions represent the critical sections.
- *Mutual Exclusion*: Every monitor is associated with one lock.
  - This lock is acquired prior to executing any function.
- *Thread Synchronization*: Monitors allow threads to synchronize their activities within the critical section, offering guarantees against deadlocks. This is achieved using condition variables.


#### Implementing Monitor Functions

1. **Start by acquiring the lock**: This is the first action of every function within a monitor.
2. **Operate on shared data**.
3. If a resource is unavailable, **temporarily release the lock**. Use a condition variable to facilitate this.
4. **Reacquire the lock** when the operation can resume. This too involves a condition variable.
5. Continue to **operate on the shared data**.
6. **Release the lock** at the function's end.

<!-- ### Example Using Semaphores: -->

<!-- The given BoundedBuffer example employs semaphores. Here's the segment you provided: -->

<!-- ```pseudo -->
<!-- Semaphore mutex = 1 --> 
<!-- Semaphore empty = N --> 
<!-- Semaphore full = 0 -->
<!-- int buffer[N] -->

<!-- BoundedBuffer::Producer() { -->
<!--     produce item -->
<!--     empty.down() // get an empty slot -->
<!--     mutex.down()  // access the buffer -->
<!--     add item to buffer -->
<!--     mutex.up()    // release the buffer -->
<!--     full.up()     // indicate a new item in buffer --> 
<!-- } -->
<!-- ``` -->

<!-- While this example demonstrates the use of semaphores, transitioning to monitors would encapsulate and streamline the process, making the code more readable and maintainable. -->





## Condition Variables
***

Condition variables are crucial tools within Monitors to help threads efficiently wait for changes to a shared state that's protected by a lock. They function as a queue for waiting threads, and they don't maintain any state themselves.

One of their primary uses is to allow threads to block inside a critical section. They achieve this by simultaneously releasing the lock when the thread is blocked.

**Key Rule**: A thread is required to possess the lock when performing operations with condition variables.

### Condition Variable Operations

1. `Wait(Lock lock)`:
   - This operation is atomic. It involves releasing the lock, transitioning the thread to the waiting queue, and then suspending the thread.
   - Upon waking, the thread re-acquires the lock before concluding the wait.
   - The thread will always be in a blocked state after this operation.

2. `Signal(Lock lock)`:
   - Its main function is to awaken a waiting thread. If no threads are waiting, this operation simply does nothing.

3. `Broadcast(Lock lock)`:
   - This awakens all waiting threads. If no threads are present in the queue, it remains inactive.

The following pseudocode show the operations within a Monitor. {{%sidenote%}}The code assumes Mesa/Hansen semantics.{{%/sidenote%}}

```c
Lock->Acquire()   // Acquires the lock. When this returns, the thread has the lock.
Lock->Release()   // Releases the lock.

CondVar::Wait(lock) {
    // Move thread to wait queue, suspend thread.
    // Upon signal, the thread wakes up and re-acquires the lock.
    ...
    return
}

CondVar::Signal(lock) {
    // Wake up a thread waiting on the condition variable.
    ...
    return
}

CondVar::Broadcast(lock) {
    // Wake up ALL threads waiting on the condition variable.
    ...
    return
}
```




## Resource Variables & Signal Semantics
***

### Resource Variables
Resource variables differ from semaphores in that they do not inherently maintain their own state.
- Every condition variable should be paired with a **resource variable** that tracks the status of that associated resource.
- These are the steps to follow with resource variables:
    1. Always verify the resource variable before invoking the `wait` on its associated condition variable. This ensures the resource is genuinely unavailable.
    2. Once the resource becomes accessible, claim it and decrease the amount being utilized.
    3. Prior to signaling completion with a resource, indicate its availability by incrementing the resource variable.

### Signal Semantics
Upon invoking `signal()`, which thread will execute? If no threads are on standby, the signaling thread continues, effectively causing the signal to be lost. When a thread (or more) is waiting, one must be chosen to execute to maintain mutual exclusion within the monitor.
    
There are two different styles for signalling:

1. **Mesa/Hansen Style**:
    - The signaling thread retains the lock and continues execution.
    - The thread on standby waits for the lock.
    - The signal is merely an indicator that the condition might be met, as shared states could have evolved.
    - This style affects performance but never impacts safety.
    - Implemented in languages like Java and most real operating systems.

2. **Hoare Style**:
    - The signaling thread relinquishes the lock, allowing the waiting thread to acquire it.
    - Signaling occurs atomically with the continuation of the waiting thread.
    - The shared state remains unchanged until the waiting thread resumes.
    - Once the previously waiting thread exits or waits again, the lock is released back to the signaling thread.
    - Typically found in many textbooks (though not yours!).

We should write code that works with either style, since we might not know what style the machine we're using uses.

After being awakened, the waiting thread might need to re-wait. Thus we must wrap `CondVar->wait()` with a `while` loop that checks the resource variable.
We also need to signal only after we increment the resource variable. These two things should let our code work with both styles.

### Signal vs. Broadcast
Substituting `broadcast()` for `signal()` is always safe, but it will impact performance.
- **Use `signal()` when**:
    - Only a single waiting thread can progress.
    - Any thread waiting on the condition variable can proceed.
- **Use `broadcast()` when**:
    - Multiple standby threads have the potential to progress.
    - The same condition variable applies to numerous predicates, meaning some waiting threads can move forward, while others cannot.
