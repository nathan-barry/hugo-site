+++
title = "Memory Management: Allocation & Relocation"
date = 2023-09-15T17:09:08-05:00
tags = ["Operating Systems Notes"]
+++

{{< toc >}}


## Address Spaces
***

- **Physical Address Space:** 
    - Represents the collection of physical memory addresses that the hardware supports.
    - Ranges from address 0 up to the maximum system address, denoted as `MAXsys`.
    
- **Logical (or Virtual) Address Space:** 
    - Denotes the set of addresses a process can access, essentially from the process's perspective.
    - Spans from address 0 to the maximum address the process can access, represented as `MAXprog`.
    
- **Segment:** 
    - A segment is essentially a contiguous block of physical memory allocated to a process.

### Basic Concepts: Address Generation

**Uniprogramming:** 
- Only a single process is executed at any given time.
- The process is always loaded starting from address 0.
- This process occupies a continuous section of memory.
- The Operating System is allocated a fixed portion of memory.
- Physical addresses can be directly generated by the compiler.
- The maximum address space available is calculated as: `(Memory Size - OS Size)`.
- Processes are protected from inadvertently accessing the Operating System's space through address checking mechanisms.

### Multiple Programs Sharing Memory

**Requirements for Effective Memory Sharing:** 

- **Transparency:** 
    - Multiple processes should co-exist in memory without any awareness of the shared memory state.
    - Processes should not be constrained or be aware of the physical portion of memory they occupy.
    
- **Safety:** 
    - Processes should not have the capability to corrupt each other.
    - The integrity of the Operating System should be maintained, protecting it from potential process corruptions.
    
- **Efficiency:** 
    - Sharing memory should not significantly degrade the performance of both the CPU and memory.



## Relocation
***

- The Operating System is positioned in the highest memory tier.
- It's assumed during compile/link time that a process begins at address 0 with its Maximum address being `Memory Size - OS Size`.
- The Operating System, when loading a process, designates a contiguous segment of memory for that process. If the process doesn't fit, the Operating System waits for an existing process to terminate.
- The initial (smallest) physical address allocated to the process is known as the `base address`. The largest address the process can access is termed the `limit address`.
    - The `base address` can also be referred to as the `relocation address`.

### Static Relocation
 
**Static Relocation:**
- The loader is responsible for adjusting the addresses within a process to mirror its actual location in memory. This is achieved by:
    - Adding the base address to the address found within the binary.
- Once the process is designated a memory location and begins executing, the Operating System ensures that it remains immobile.

**Note:** In this revised format, I've paraphrased the provided notes to make them more comprehensive and fluent. Readers can easily follow through with the transitions between concepts and gain a clearer understanding of memory management in Operating Systems.

### Dynamic Relocation

**Basics of Dynamic Relocation:** 
- Unlike static relocation, dynamic relocation allows for the movement of processes in memory during their execution. This is achieved through hardware assistance.
- When operating, the hardware:
    1. Adds a relocation register (often termed the "base") to the virtual address to determine the physical address.
    2. Compares the resultant address with a limit register. The address must always be lesser than the limit. If it isn't, the processor flags an exception.

### Pros & Cons of Dynamic Relocation

**Advantages:**
1. **Multiprogramming:** Dynamic relocation supports multiprogramming, allowing multiple processes to co-exist and execute in memory.
2. **Flexibility:** As processes can be moved around, memory allocation is more flexible.
3. **Protection:** Dynamic relocation ensures that each process's memory space is protected from other processes.

**Disadvantages:**
1. **Contiguity:** Processes must be contiguous in memory, which can sometimes be a limitation.
2. **Memory Sharing:** Sharing memory between processes becomes challenging.
3. **Memory Overhead:** The system checks memory access for every instruction, which can be performance-intensive.
4. **Limited Growth:** Processes have limited room to grow within their allocated memory space.

### Enabling Multiprogramming: Tracking Free Space

**How Free Space is Tracked:**
- To effectively manage memory, the Operating System needs to keep track of:
    1. Memory that's available (often termed as "holes").
    2. Memory that's currently in use.
- Given the dynamic nature of process lifecycle (creation, growth, termination), this state can change rapidly.
- The Operating System typically tracks this using a linked list structure called the **free list**.



## Memory Allocation and Placement Policies
***

When a process requests memory, the Operating System must determine where to place that process in memory. The goal of memory allocation policies is to minimize wasted space. There are two primary sources of wasted memory:

- **External Fragmentation:** Unused memory spaces that reside between allocated units. This is analogous to having two separate tables allocated for two people, but a party of four needs to be accommodated.

- **Internal Fragmentation:** Unused memory spaces within an allocated unit. This can be likened to seating three people at a table designed for four.


### First-Fit Memory Allocation

**Definition:** For a request of `n` bytes, the first available block of memory that is greater than or equal to `n` is allocated. In other words, it allocates the first block of memory that it finds.

- **Goal:** Prioritize simplicity in the implementation.
- **Requirements:** 
    - Free block list should be sorted by address.
    - Allocating needs a search for an appropriate block.
    - De-allocating requires checks to possibly merge the freed block with adjacent free blocks.

### Best-Fit Memory Allocation

**Definition:** For a request of `n` bytes, the smallest block of memory that is larger than or equal to `n` is chosen. In other words, we allocate from the smallest block of memory that still fits our number of bytes.

- **Goals:** 
    - Prevent fragmentation of large free blocks.
    - Minimize resulting external fragments.
- **Requirements:** 
    - The free block list should be sorted by size.
    - Allocating needs a search for the best fit.
    - De-allocating requires checks to possibly merge the freed block with adjacent free blocks.

### Worst-Fit Memory Allocation

**Definition:** For a request of `n` bytes, the largest available block of memory that is larger than or equal to `n` is chosen. In other words, we allocate from the largest chunk of memory we find.

- **Goals:** 
    - Prevent accumulation of many tiny memory fragments.
- **Requirements:** 
    - The free block list should be sorted by size.
    - Allocation is generally quick as you select the largest block.
    - De-allocating requires checks to possibly merge the freed block with adjacent free blocks.


Each of the above policies has its own set of advantages and disadvantages. For example, while the first-fit might be fast, it may lead to more external fragmentation over time. Best-fit might reduce fragmentation but can be computationally expensive, and worst-fit might end up wasting more memory in the long run. The choice between them often depends on the specific use case and system requirements.


## Strategies to Eliminate Fragmentation
***

### Compaction

**Definition:** 
Compaction involves relocating processes so that all the free memory is together in one large block. The programs are adjacent to each other, leaving no spaces in between. This strategy is used to eliminate external fragmentation.

### Swapping

**Definition:** 
Swapping is a technique where a process is moved from main memory to the disk (swapped out) and then brought back into the main memory (swapped in) for execution at a later time. This method is employed when the system requires more memory resources than are available.

**Steps Involved in Swapping:**
1. **Suspend the Process:** The process which is to be swapped out is first suspended, ensuring it is not currently in execution.
2. **Move Process to Disk:** The address space of the suspended process is transferred to a pre-determined storage area on the disk.
3. **Reallocate Memory:** The memory that was previously occupied by the suspended process is now freed up and can be allocated to other processes.

**Benefits:**
- Swapping can be a useful way to maximize the use of primary memory. By swapping out processes that aren't currently needed and bringing in those that are, the OS can ensure that the most crucial processes get the resources they need.

**Challenges:**
- The act of swapping can be time-consuming, especially if it happens frequently (known as thrashing). The time taken to move data between the main memory and the disk can significantly impact system performance.

Both compaction and swapping are methods used by operating systems to manage memory efficiently, and their usage depends on system requirements and constraints.
